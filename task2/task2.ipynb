{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 7176600,
          "sourceType": "datasetVersion",
          "datasetId": 4147300
        },
        {
          "sourceId": 7184308,
          "sourceType": "datasetVersion",
          "datasetId": 4153031
        },
        {
          "sourceId": 7186775,
          "sourceType": "datasetVersion",
          "datasetId": 4154868
        },
        {
          "sourceId": 7186806,
          "sourceType": "datasetVersion",
          "datasetId": 4154892
        },
        {
          "sourceId": 7192726,
          "sourceType": "datasetVersion",
          "datasetId": 4159341
        }
      ],
      "dockerImageVersionId": 30616,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installing all the dependencies"
      ],
      "metadata": {
        "id": "Z2xdYZCPxtcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install av\n",
        "!pip install pandas\n",
        "!pip install transformers\n",
        "!pip install ast\n",
        "!pip install requests\n",
        "!pip install numpy\n",
        "!pip install torch"
      ],
      "metadata": {
        "trusted": true,
        "id": "dJ3cTodPxtck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing all the necessary libraries and functions"
      ],
      "metadata": {
        "id": "Mmn7hWlzxtco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import transformers\n",
        "import av\n",
        "import re\n",
        "import ast\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoImageProcessor, AutoTokenizer, VisionEncoderDecoderModel,AutoModel ,BitsAndBytesConfig, AutoModelForCausalLM\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import requests"
      ],
      "metadata": {
        "trusted": true,
        "id": "K1VaR2hpxtcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "_Pe9lsZextcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the test dataset and company-to-sector mapping\n",
        "Enter path of the test dataset and company-to-sector mapping excel files"
      ],
      "metadata": {
        "id": "wA6vHC7txtcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = pd.read_excel('/kaggle/input/test-ds/test_data.xlsx')\n",
        "company2sector = pd.read_excel('/kaggle/input/company2sector/company2sector (1).xlsx')"
      ],
      "metadata": {
        "trusted": true,
        "id": "y7gNjeESxtcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load all the models ,tokenizers and image processors"
      ],
      "metadata": {
        "id": "7b-RQwlMxtcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor_1 = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
        "tokenizer_vid = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model_vid = VisionEncoderDecoderModel.from_pretrained(\"Neleac/timesformer-gpt2-video-captioning\").to(device)\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model_img = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\").to(device)\n",
        "model_final = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", quantization_config=bnb_config, device_map=\"auto\")\n",
        "tokenizer_final = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "DrXE3N0Extcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions to generate captions ,prompts and final tweet"
      ],
      "metadata": {
        "id": "wHostOZQxtcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "count1 = 0\n",
        "\n",
        "def video_caption(video_url):\n",
        "    try:\n",
        "\n",
        "        urls_with_bitrate = re.findall(r\"url='(.*?)', bitrate=(\\d+|None)\", video_url)\n",
        "\n",
        "\n",
        "        filtered_urls = [url for url, bitrate in urls_with_bitrate if bitrate.lower() != 'none']\n",
        "        final_url = filtered_urls[0]\n",
        "        with requests.get(final_url, stream=True) as response:\n",
        "            response.raise_for_status()\n",
        "            with open(\"downloaded_video.mp4\", \"wb\") as f:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    f.write(chunk)\n",
        "\n",
        "        container = av.open(\"downloaded_video.mp4\")\n",
        "        seg_len = container.streams.video[0].frames\n",
        "        clip_len = model_vid.config.encoder.num_frames\n",
        "        indices = set(np.linspace(0, seg_len, num=clip_len, endpoint=False).astype(np.int64))\n",
        "        frames = []\n",
        "        container.seek(0)\n",
        "\n",
        "        for i, frame in enumerate(container.decode(video=0)):\n",
        "            if i in indices:\n",
        "                frames.append(frame.to_ndarray(format=\"rgb24\"))\n",
        "        gen_kwargs = {\n",
        "            \"min_length\": 10,\n",
        "            \"max_length\": 30,\n",
        "            \"num_beams\": 4,\n",
        "        }\n",
        "        pixel_values = processor_1(frames, return_tensors=\"pt\").pixel_values.to(device)\n",
        "        tokens = model_vid.generate(pixel_values, **gen_kwargs)\n",
        "        return tokenizer_vid.batch_decode(tokens, skip_special_tokens=True)[0]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return \"blank\"\n",
        "\n",
        "def img_caption(img_url):\n",
        "    try:\n",
        "        image_data_ast = ast.parse(img_url)\n",
        "        last_url = None\n",
        "\n",
        "        for node in ast.walk(image_data_ast):\n",
        "            if isinstance(node, ast.Str) and \"https://\" in node.s:\n",
        "                last_url = node.s\n",
        "        raw_image = Image.open(requests.get(last_url, stream=True).raw).convert('RGB')\n",
        "        inputs = processor(raw_image, return_tensors=\"pt\").to(device)\n",
        "        return processor.decode(model_img.generate(**inputs)[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return \"blank\"\n",
        "\n",
        "\n",
        "def captions(url):\n",
        "    global count\n",
        "    count+=1\n",
        "    if (count%500 == 499):\n",
        "        print(count)\n",
        "    if url[1] == 'V' or url[1] == 'G':\n",
        "        return video_caption(url)\n",
        "    else:\n",
        "        return img_caption(url)\n",
        "\n",
        "def get_sector(company):\n",
        "    return company2sector[company2sector['Company']== company]['Sector'].values[0]\n",
        "\n",
        "def get_prompt(row):\n",
        "    if row['caption'] != 'blank':\n",
        "        result=(\n",
        "            \"Company name : \" + row['inferred company'] + \"\\n\" +\n",
        "            \"Operational sectors : \" + row['sector'] + \"\\n\" +\n",
        "            \"Likes of the tweet : \" + str(row['likes']) + \"\\n\" +\n",
        "            \"Image/Video Description : \" + row['caption'] + \"\\n\" +\n",
        "            \"Goal: Generate a tweet text for this company to increase brand awareness and to maximize the likes.The output should consist only of tweet text. \")\n",
        "    else:\n",
        "        result=(\n",
        "            \"Company name : \" + row['inferred company'] + \"\\n\" +\n",
        "            \"Operational sectors : \" + row['sector'] + \"\\n\" +\n",
        "            \"Likes of the tweet : \" + str(row['likes']) + \"\\n\" +\n",
        "            \"Goal: Generate a tweet text for this company to increase brand awareness and to maximize the likes.The output should consist only of tweet text. \")\n",
        "\n",
        "def gen_tweet(prompt):\n",
        "    global count1\n",
        "    count1+=1\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "\n",
        "    encodeds = tokenizer_final.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "\n",
        "    model_inputs = encodeds.to(device)\n",
        "\n",
        "\n",
        "    generated_ids = model_final.generate(model_inputs, max_new_tokens=200, do_sample=True ,pad_token_id= tokenizer_final.eos_token_id)\n",
        "    decoded = tokenizer_final.batch_decode(generated_ids)\n",
        "    if count1%500 == 499:\n",
        "        print(count1)\n",
        "    return re.findall(r'\\[/INST\\](.*?)<\\/s>', decoded[0])\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "TrlU8Ujlxtcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating captions for the Video/Image/GIF"
      ],
      "metadata": {
        "id": "cXLLmIYYxtct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.loc[:, 'caption'] = ds['media'].apply(captions)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RtrSW-85xtct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing the sectors in which the company works in the dataframe"
      ],
      "metadata": {
        "id": "J84jWdG3xtct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.loc[:, 'sector'] = ds['inferred company'].apply(get_sector)"
      ],
      "metadata": {
        "trusted": true,
        "id": "CvEEKkkKxtcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating prompts for the LLM to generate tweet"
      ],
      "metadata": {
        "id": "SLGdKEYmxtcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds['prompt'] = ds.apply(get_prompt, axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "73teDDbPxtcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating outputs from the prompts"
      ],
      "metadata": {
        "id": "2CBf4ezCxtcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.loc[:, 'output'] = ds['prompt'].apply(gen_tweet)"
      ],
      "metadata": {
        "trusted": true,
        "id": "wbC4y5auxtcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-processing (Cleaning the tweet)"
      ],
      "metadata": {
        "id": "D2ZA0FdYyD10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funtion to remove additional brackets enclosing tweets"
      ],
      "metadata": {
        "id": "TNDAUDmPyGJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_tweet(tweet):\n",
        "    if tweet.startswith(\"[' \\\"\"):\n",
        "        last_quote_index = tweet.rfind('\"')\n",
        "        if last_quote_index != -1:\n",
        "            cleaned_tweet = tweet[4:last_quote_index] + tweet[last_quote_index + 1:-3]\n",
        "            cleaned_tweet = cleaned_tweet.replace(\"\\\\'\", \"'\")\n",
        "            return cleaned_tweet\n",
        "    elif tweet.startswith(\"['\"):\n",
        "        return tweet[3:-2].replace(\"\\\\'\", \"'\")\n",
        "    elif tweet.startswith('[\"') and tweet.endswith('\"]'):\n",
        "        return tweet[2:-2].replace(\"\\\\'\", \"'\")\n",
        "    return tweet"
      ],
      "metadata": {
        "id": "2KczhalPyJr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to remove obvious prefixes\n",
        "These prefixes would never appear in a tweet, they just state whether the text is likely to be a tweet or a caption."
      ],
      "metadata": {
        "id": "JKA1_-lgyPR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefixes_to_handle = ['Tweet: \"', 'Tweet: ', 'Hey tweet: ', 'Crafting a captivating News@Express tweet: \"',\n",
        "                      ' Tweet: ', 'Tweet Text: \"', 'Tweet text: \"', 'Caption text: \"', 'Caption: \"' ]\n",
        "def clean_tweet_further(tweet):\n",
        "  if any(tweet.startswith(prefix) for prefix in prefixes_to_handle):\n",
        "        for prefix in prefixes_to_handle:\n",
        "            if tweet.startswith(prefix):\n",
        "                if prefix.endswith('\"'):\n",
        "                    start_index = tweet.find(prefix) + len(prefix)\n",
        "                    end_index = tweet.find('\"', start_index)\n",
        "                    if end_index != -1:\n",
        "                        return tweet[start_index:end_index] + tweet[end_index + 1:]\n",
        "                else:\n",
        "                    return tweet[len(prefix):]\n",
        "  return tweet"
      ],
      "metadata": {
        "id": "OgbB2t67yMdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to remove LLM text before the generated tweet\n",
        "The LLM may generate a message such as: *Sure, this could be the tweet: \" < actual tweet > \"*\n",
        "\n",
        "This function extracts the actual tweet."
      ],
      "metadata": {
        "id": "VlPb93VjyTvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_llm_text(text):\n",
        "    parts = text.split(': \"')\n",
        "    if len(parts) > 1:\n",
        "        extracted_text = parts[1].split('\"')[0]\n",
        "        return extracted_text\n",
        "    return text"
      ],
      "metadata": {
        "id": "GmYqh_gAyTUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying the post-processing functions to the generated tweets"
      ],
      "metadata": {
        "id": "MzwbI8nMydGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds['output'] = ds['output'].apply(clean_tweet)\n",
        "ds['output'] = ds['output'].apply(clean_tweet_further)\n",
        "ds.loc[ds['inferred company'] != 'express', 'output'] = ds.loc[ds['inferred company'] != 'express', 'output'].apply(remove_llm_text)"
      ],
      "metadata": {
        "id": "U-MOi8xuyZyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the final dataframe in the form of excel"
      ],
      "metadata": {
        "id": "p1xYuu98xtcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds.to_excel('content_simulation_tes_output.xlsx')"
      ],
      "metadata": {
        "trusted": true,
        "id": "9ZEwLuIsxtcv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}